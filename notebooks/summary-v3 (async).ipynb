{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../.env\")\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI-API-KEY')\n",
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "from functools import wraps, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prevents the metadata from being None which causes errors with the vectorstore\n",
    "def sanitize_metadata(data):\n",
    "    for item in data:\n",
    "        meta = item.metadata\n",
    "        for key, value in meta.items():\n",
    "            if value is None:\n",
    "                meta[key] = \"\"\n",
    "    return data\n",
    "\n",
    "def unpack (data):\n",
    "    return [{'page' : idx + 1, 'content' : page.page_content, 'metadata' : page.metadata} for idx, page in enumerate(data)]\n",
    "\n",
    "def dot_product_similarity(doc_data: List[Dict], query_data: Dict) -> List[Tuple[int, float]]:\n",
    "    query_embedding = query_data['embedding']\n",
    "    doc_embeddings = [page['embedding'] for page in doc_data]\n",
    "    tuples_list = [(page['page'], np.dot(query_embedding, embedding)) for page, embedding in zip(doc_data, doc_embeddings)]\n",
    "    ordered_tuples = sorted(tuples_list, key=itemgetter(1), reverse=True)\n",
    "    top_five_tuples = ordered_tuples[:5]\n",
    "    return top_five_tuples\n",
    "\n",
    "def embed_query(query: str):\n",
    "    base_embeddings = OpenAIEmbeddings()\n",
    "    embedding = base_embeddings.embed_query(query)\n",
    "    return {\"query\" : query, \"embedding\" : embedding}\n",
    "\n",
    "def embed_doc(text_list : List[str]):\n",
    "    base_embeddings = OpenAIEmbeddings()\n",
    "    doc_embeddings = base_embeddings.embed_documents(text_list)\n",
    "    return doc_embeddings\n",
    "\n",
    "def get_context(query_data, doc_data: List[Dict]) -> List[Dict]:\n",
    "    top_five_tuples = dot_product_similarity(doc_data, query_data)\n",
    "    context = []\n",
    "    for item in top_five_tuples:\n",
    "        page = item[0]\n",
    "        data = {'page': page, 'similarity' : item[1], 'text': doc_data[page - 1]['content'], 'metadata' : doc_data[page - 1]['metadata']}\n",
    "        context.append(data)\n",
    "    return context\n",
    "\n",
    "def get_tokens(string: str, model: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def format_context(context: List[Dict], model: str, token_limit : int) -> str:\n",
    "    \"\"\"Returns a string of the first 1024 tokens of the context.\"\"\"\n",
    "    context_string = \"\"\n",
    "    meta_list = []\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    for idx, item in enumerate(context):\n",
    "        sanitized_text = item['text'].replace(\"\\n\", \" \")\n",
    "        context_string += f\"Page: {item['page']}\\n\\nText: {sanitized_text}\\n\\n\"\n",
    "        meta_list.append(item['metadata'])\n",
    "        tokens = get_tokens(context_string, model)\n",
    "        if tokens > token_limit:\n",
    "            encoded_text = encoding.encode(context_string)\n",
    "            # cut it down to the token limit\n",
    "            encoded_text = encoded_text[:token_limit]\n",
    "            # decode it back to a string\n",
    "            context_string = encoding.decode(encoded_text)\n",
    "            # some testing to make sure it worked\n",
    "            tokens = get_tokens(context_string, model)\n",
    "            assert tokens <= token_limit, f\"format context function failed to cut context down far enough. tokens: {tokens}\"\n",
    "            break\n",
    "    return context_string, meta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    # Replace any non-alphanumeric character with a space\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Replace any multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Completion:\n",
    "    def __init__(self, temperature, max_tokens, stream=False, model=\"text-davinci-003\", **kwargs):\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.stream = stream\n",
    "        self.model = model\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        raw_response = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=text,\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=self.max_tokens,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        if self.stream:\n",
    "            return raw_response\n",
    "        elif len(raw_response['choices']) > 1:\n",
    "            return [choice['text'].strip() for choice in raw_response['choices']]\n",
    "        else:\n",
    "            return raw_response['choices'][0]['text'].strip()\n",
    "\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, temperature, system_message=\"You are a helpful assistant.\", messages=None, model='gpt-3.5-turbo'):\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        if messages is not None:\n",
    "            self.messages += [{\"role\": \"user\", \"content\": message} for message in messages]\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    def __call__(self, user_message: str):\n",
    "        user_message = {\"role\": \"user\", \"content\": user_message}\n",
    "        self.messages.append(user_message)\n",
    "        raw_response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        response_message = raw_response['choices'][0]['message']['content'].strip()\n",
    "        self.messages.append(response_message)\n",
    "        return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_wrap(func):\n",
    "    @wraps(func)\n",
    "    async def run(*args, loop=None, executor=None, **kwargs):\n",
    "        if loop is None:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        pfunc = partial(func, *args, **kwargs)\n",
    "        return await loop.run_in_executor(executor, pfunc)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response(temperature, model, message):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    raw_response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    response_message = raw_response['choices'][0]['message']['content'].strip()\n",
    "    return response_message\n",
    "\n",
    "async_chat_response = async_wrap(chat_response)\n",
    "\n",
    "async def asyncChatResponse(temperature, model, message, response_list, messages_list):\n",
    "    start_time = time.perf_counter()\n",
    "    response = await async_chat_response(temperature, model, message)\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "\n",
    "    index = messages_list.index(message) + 1\n",
    "    length = len(messages_list)\n",
    "    print(f\"Response {index} of {length} complete.\")\n",
    "    print(f\"Response time: {elapsed:0.2f} seconds.\")\n",
    "    response_list.append(response)\n",
    "\n",
    "async def run_chat_async(messages_list, response_list, temperature=0.7, model='gpt-3.5-turbo'):\n",
    "    await asyncio.gather(*(asyncChatResponse(temperature, model, message, response_list, messages_list) for message in messages_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(temperature, model, prompt):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    raw_response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    responses = [choice['text'].strip() for choice in raw_response['choices']]\n",
    "    return responses\n",
    "\n",
    "async_get_response = async_wrap(get_response)\n",
    "\n",
    "async def asyncGetResponse(temperature, model, prompt, response_list, prompts_list):\n",
    "    start_time = time.perf_counter()\n",
    "    response = await async_get_response(temperature, model, prompt)\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "\n",
    "    index = prompts_list.index(prompt) + 1\n",
    "    length = len(prompts_list)\n",
    "    print(f\"Response {index} of {length} complete.\")\n",
    "    print(f\"Response time: {elapsed:0.2f} seconds.\")\n",
    "    response_list.append(response)\n",
    "\n",
    "async def run_completion_async(prompts_list, response_list, temperature=0.7, model='text-davinci-003'):\n",
    "    await asyncio.gather(*(asyncGetResponse(temperature, model, prompt, response_list, prompts_list) for prompt in prompts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am a digital assistant.', 'My name is Chris.', 'My favorite color is blue.']\n"
     ]
    }
   ],
   "source": [
    "com = Completion(temperature=0.7, max_tokens=1000, stream=False, model=\"text-davinci-003\")\n",
    "\n",
    "print(com(['who are you', 'what is your name', 'what is your favorite color?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 4 of 10 complete.\n",
      "Response time: 1.27 seconds.\n",
      "Response 8 of 10 complete.\n",
      "Response time: 1.34 seconds.\n",
      "Response 5 of 10 complete.\n",
      "Response time: 1.41 seconds.\n",
      "Response 2 of 10 complete.\n",
      "Response time: 1.46 seconds.\n",
      "Response 10 of 10 complete.\n",
      "Response time: 1.68 seconds.\n",
      "Response 1 of 10 complete.\n",
      "Response time: 1.77 seconds.\n",
      "Response 3 of 10 complete.\n",
      "Response time: 1.78 seconds.\n",
      "Response 9 of 10 complete.\n",
      "Response time: 1.99 seconds.\n",
      "Response 6 of 10 complete.\n",
      "Response time: 2.29 seconds.\n",
      "Response 7 of 10 complete.\n",
      "Response time: 2.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "messages_list = [\n",
    "    \"What is your favorite color?\",\n",
    "    \"What is your second favorite color?\",\n",
    "    \"What is your third favorite color?\", \n",
    "    \"What is your favorite food?\",\n",
    "    \"What is your favorite animal?\", \n",
    "    \"What is your favorite movie?\", \n",
    "    \"What is your favorite book?\",\n",
    "    \"What is your favorite song?\",\n",
    "    \"What is your favorite band?\",\n",
    "    \"What is your favorite sport?\",\n",
    "]\n",
    "\n",
    "response_list = []\n",
    "await run_chat_async(messages_list, response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mongodoc:\n",
    "    def __init__(self, fpath : str):\n",
    "        self.fpath = fpath\n",
    "\n",
    "    def process_doc(self):\n",
    "        loader = PyMuPDFLoader(self.fpath)\n",
    "        # load the data\n",
    "        unsanitized = loader.load()\n",
    "        # make sure the metadata is not None\n",
    "        data = sanitize_metadata(unsanitized)\n",
    "        # get the doc embeddings\n",
    "        doc_embeddings = embed_doc([page.page_content for page in data])\n",
    "        # unpack the data and add the embeddings\n",
    "        mongodoc = unpack(data)\n",
    "        mongodoc = [{**page, \"embedding\": embedding} for page, embedding in zip(mongodoc, doc_embeddings)]\n",
    "\n",
    "        self.data = mongodoc\n",
    "        self.page_text = ' '.join([sanitize_text(page['content']) for page in mongodoc])\n",
    "        self.metadata = [page['metadata'] for page in mongodoc]\n",
    "        return self\n",
    "    \n",
    "    def get_chunks(self, chunk_size : int):\n",
    "        enc = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "        tokens = enc.encode(self.page_text)\n",
    "        # split into chunks of 2800 tokens\n",
    "        chunks = [tokens[i:i+2800] for i in range(0, len(tokens), 2800)]\n",
    "        # decode chunks\n",
    "        decoded = [enc.decode(chunk) for chunk in chunks]\n",
    "        self.chunks = decoded\n",
    "        return self\n",
    "    \n",
    "    def get_citation(self, format: str):\n",
    "        citation_chat = Chat(temperature=0.9)\n",
    "        get_citation_prompt = f\"Use this metadata to generate a ciation in {format} format: \\n\\n{self.metadata}\"\n",
    "        final_citation = citation_chat(get_citation_prompt)\n",
    "        self.citation = final_citation\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chain:\n",
    "    def __init__(self, mongodoc: Mongodoc):\n",
    "        self.mongodoc = mongodoc\n",
    "        # pass all the attributes from the mongodoc to the chain\n",
    "        for attr in dir(mongodoc):\n",
    "            if not callable(getattr(mongodoc, attr)) and not attr.startswith(\"__\"):\n",
    "                setattr(self, attr, getattr(mongodoc, attr))\n",
    "\n",
    "    def link_1(self):\n",
    "        print(\"Starting Link 1:\")\n",
    "        citation_qualifier = f\"Use this citation: {self.citation} to cite your work.\"\n",
    "        main_ideas_prompt = f\"Identify and list 2-3 main ideas from the context. {citation_qualifier}\"\n",
    "        quotes_prompt = f\"Identify and list 2-3 relevant quotes from the context. {citation_qualifier}\"\n",
    "        passages_prompt = f\"Identify and list 2-3 relevant passages from the context. {citation_qualifier}\"\n",
    "\n",
    "        prompts = [\n",
    "            {\"type\": \"main_ideas\", \"prompt\": main_ideas_prompt},\n",
    "            {\"type\": \"quotes\", \"prompt\": quotes_prompt},\n",
    "            {\"type\": \"passages\", \"prompt\": passages_prompt}\n",
    "        ]\n",
    "\n",
    "        system_message = \"You are a helpful assistant that is very good at problem solving who thinks step by step. You always cite direct quotes and paraphrases with the appropriate in-text citation.\"\n",
    "\n",
    "        responses = []\n",
    "        for idx, chunk in enumerate(self.chunks):\n",
    "            print(f\"Chunk {idx+1} of {len(self.chunks)}\")\n",
    "            page_responses = []\n",
    "            for prompt in prompts:\n",
    "                print(prompt[\"type\"])\n",
    "                chat = Chat(temperature=0.9, system_message=system_message)\n",
    "                response = chat(f\"CONTEXT:{chunk}\\n\\nQUERY:{prompt['prompt']}\")\n",
    "                page_responses.append(\n",
    "                    {\"Chunk\": idx+1, \"prompt_type\": prompt[\"type\"], \"response\": response})\n",
    "            responses.append(page_responses)\n",
    "        self.link_1_responses = responses\n",
    "\n",
    "        print(\"Link 1 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_1(self):\n",
    "        for page in self.link_1_responses:\n",
    "            for response in page:\n",
    "                print(f'Chunk: {response[\"Chunk\"]}\\nType: {response[\"prompt_type\"]}\\n\\nResponse:\\n{response[\"response\"]}')\n",
    "    \n",
    "    def link_2(self):\n",
    "        print(\"Starting Link 2:\")\n",
    "        llm = Completion(temperature=0.9, max_tokens=1000)\n",
    "        summary_responses = []\n",
    "        for page in self.link_1_responses:\n",
    "            combine_prompt = f\"Combine the following Main Ideas:\\n{page[0]['response']}\\n\\nQuotes:\\n{page[1]['response']}\\n\\nPassages:\\n{page[2]['response']}\\n\\ninto a coherent writing. Retain any in-text citations, don't add any new citations except for {self.citation}\\n\\nSUMMARY:\"\n",
    "            summary_response = llm(combine_prompt)\n",
    "            summary_responses.append(summary_response)\n",
    "        self.link_2_responses = summary_responses\n",
    "        print(\"Link 2 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_2(self):\n",
    "        for response in self.link_2_responses:\n",
    "            print(response)\n",
    "\n",
    "    def link_3(self):\n",
    "        print(\"Starting Link 3:\")\n",
    "        llm = Completion(temperature=0.9, max_tokens=1000)\n",
    "        prompt = f\"combine the following passages:{' '.join([summary for summary in self.link_2_responses])} into an essay. Retain your in-text citations and make sure to include a reference list at the end of your essay using this citation: {self.citation}. Make sure you dont repeat anything.\"\n",
    "        response = llm(prompt)\n",
    "        self.link_3_response = response\n",
    "        print(\"Link 3 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_3(self):\n",
    "        print(self.link_3_response)\n",
    "\n",
    "    def link_4(self):\n",
    "        with open(\"../data/apa_guidelines.txt\", \"r\") as f:\n",
    "            guidelines = f.read()\n",
    "\n",
    "        print(\"Starting Link 4:\")\n",
    "        llm = Chat(temperature=0.9)\n",
    "        guidelines = \"https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/general_format.html\"\n",
    "        prompt = f\"Essay:{self.link_3_response}\\n\\nFinalize thee essay based on the following APA guidelines: {guidelines}\"\n",
    "        response = llm(prompt)\n",
    "        self.link_4_response = response\n",
    "        print(\"Link 4 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_4(self):\n",
    "        print(self.link_4_response)\n",
    "\n",
    "    def chain(self):\n",
    "        start = time.perf_counter()\n",
    "        print(\"Starting Chain\")\n",
    "        self.link_1().link_2().link_3().link_4()\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"Chain Complete in {elapsed:0.2f} seconds.\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncChain:\n",
    "    def __init__(self, mongodoc: Mongodoc):\n",
    "        self.mongodoc = mongodoc\n",
    "        # pass all the attributes from the mongodoc to the chain\n",
    "        for attr in dir(mongodoc):\n",
    "            if not callable(getattr(mongodoc, attr)) and not attr.startswith(\"__\"):\n",
    "                setattr(self, attr, getattr(mongodoc, attr))\n",
    "\n",
    "    async def link_1(self):\n",
    "        print(\"Starting Link 1:\")\n",
    "        citation_qualifier = f\"Use this citation: {self.citation} to cite your work.\"\n",
    "        main_ideas_prompt = f\"Identify and list 2-3 main ideas from the context. {citation_qualifier}\"\n",
    "        quotes_prompt = f\"Identify and list 2-3 relevant quotes from the context. {citation_qualifier}\"\n",
    "        passages_prompt = f\"Identify and list 2-3 relevant passages from the context. {citation_qualifier}\"\n",
    "\n",
    "        prompts = [\n",
    "            {\"type\": \"main_ideas\", \"prompt\": main_ideas_prompt},\n",
    "            {\"type\": \"quotes\", \"prompt\": quotes_prompt},\n",
    "            {\"type\": \"passages\", \"prompt\": passages_prompt}\n",
    "        ]\n",
    "\n",
    "        system_message = \"You are a helpful assistant that is very good at problem solving who thinks step by step. You always cite direct quotes and paraphrases with the appropriate in-text citation.\"\n",
    "\n",
    "        responses = []\n",
    "        hardcode_prompts = [[f\"CONTEXT:{chunk}\\n\\nQUERY:{prompt['prompt']}\" for prompt in prompts]\n",
    "                            for idx, chunk in enumerate(self.chunks)]\n",
    "        flattened_prompts = [\n",
    "            item for sublist in hardcode_prompts for item in sublist]\n",
    "\n",
    "        await run_chat_async(flattened_prompts, responses)\n",
    "\n",
    "        # split the responses into chunks of 3\n",
    "        response_chunks = []\n",
    "        n = len(prompts)\n",
    "        for i in range(0, len(responses), n):\n",
    "            response_chunk = responses[i:i+n]\n",
    "            response_chunks.append(response_chunk)\n",
    "\n",
    "        # create a list of dicts\n",
    "        response_dicts = []\n",
    "        for idx, chunk in enumerate(response_chunks):\n",
    "            page_dict = []\n",
    "            for prompt, response in zip(prompts, chunk):\n",
    "                page_dict.append(\n",
    "                    {\"Chunk\": idx+1, \"prompt_type\": prompt[\"type\"], \"response\": response})\n",
    "            response_dicts.append(page_dict)\n",
    "        self.link_1_responses = responses\n",
    "        # format [[{chunk: 1, prompt_type: main_ideas, response: ...}, ...], ...]\n",
    "        self.link_1_response_dicts = response_dicts\n",
    "        print(\"Link 1 Complete\")\n",
    "        return self\n",
    "\n",
    "    def print_link_1(self):\n",
    "        for page in self.link_1_response_dicts:\n",
    "            for response in page:\n",
    "                print(f'Chunk: {response[\"Chunk\"]}\\nType: {response[\"prompt_type\"]}\\n\\nResponse:\\n{response[\"response\"]}\\n')\n",
    "\n",
    "    async def link_2(self):\n",
    "        print(\"Starting Link 2:\")\n",
    "        llm = Completion(temperature=0.9, max_tokens=1000)\n",
    "    \n",
    "    async def link_2(self):\n",
    "        print(\"Starting Link 2:\")\n",
    "        prompts = []\n",
    "        for page in self.link_1_response_dicts:\n",
    "            combine_prompt = f\"Combine the following Main Ideas:\\n{page[0]['response']}\\n\\nQuotes:\\n{page[1]['response']}\\n\\nPassages:\\n{page[2]['response']}\\n\\ninto a coherent writing. Retain any in-text citations, don't add any new citations except for {self.citation}\\n\\nSUMMARY:\"\n",
    "            prompts.append(combine_prompt)\n",
    "        responses = []\n",
    "        await run_completion_async(prompts, responses)\n",
    "        self.link_2_responses = responses\n",
    "        print(\"Link 2 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_2(self):\n",
    "        for response in self.link_2_responses:\n",
    "            print(response)\n",
    "\n",
    "    def link_3(self):\n",
    "        print(\"Starting Link 3:\")\n",
    "        chat = Chat(temperature=0.9)\n",
    "        prompt = f\"Combine the following passages:{' '.join([summary for summary in self.link_2_responses])} into an essay. Retain your in-text citations and make sure to include a reference list at the end of your essay using this citation: {self.citation}.\"\n",
    "        response = chat(prompt)\n",
    "        self.link_3_response = response\n",
    "        print(\"Link 3 Complete\")\n",
    "        return self\n",
    "    \n",
    "    def print_link_3(self):\n",
    "        print(self.link_3_response)\n",
    "\n",
    "    async def chain(self):\n",
    "        overall_start = time.perf_counter()\n",
    "        start = time.perf_counter()\n",
    "        print(\"Starting Chain\")\n",
    "        await self.link_1()\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"Link 1 Complete in {elapsed:0.2f} seconds.\")\n",
    "        start = time.perf_counter()\n",
    "        await self.link_2()\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"Link 2 Complete in {elapsed:0.2f} seconds.\")\n",
    "        start = time.perf_counter()\n",
    "        self.link_3()\n",
    "        print(f\"Link 3 Complete in {elapsed:0.2f} seconds.\")\n",
    "        elapsed = time.perf_counter() - start\n",
    "        overall_elapsed = time.perf_counter() - overall_start\n",
    "        print(f\"Chain Complete in {overall_elapsed:0.2f} seconds.\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../data/powers2017.pdf\"\n",
    "fpath = \"../data/moore-et-al-2022.pdf\"\n",
    "doc = Mongodoc(fpath).process_doc().get_chunks(2800).get_citation(\"APA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Link 1:\n",
      "Response 14 of 15 complete.\n",
      "Response time: 3.49 seconds.\n",
      "Response 8 of 15 complete.\n",
      "Response time: 3.58 seconds.\n",
      "Response 1 of 15 complete.\n",
      "Response time: 4.21 seconds.\n",
      "Response 3 of 15 complete.\n",
      "Response time: 4.28 seconds.\n",
      "Response 7 of 15 complete.\n",
      "Response time: 4.31 seconds.\n",
      "Response 11 of 15 complete.\n",
      "Response time: 4.46 seconds.\n",
      "Response 4 of 15 complete.\n",
      "Response time: 4.92 seconds.\n",
      "Response 9 of 15 complete.\n",
      "Response time: 5.13 seconds.\n",
      "Response 2 of 15 complete.\n",
      "Response time: 5.30 seconds.\n",
      "Response 10 of 15 complete.\n",
      "Response time: 5.49 seconds.\n",
      "Response 12 of 15 complete.\n",
      "Response time: 5.84 seconds.\n",
      "Response 6 of 15 complete.\n",
      "Response time: 6.46 seconds.\n",
      "Response 15 of 15 complete.\n",
      "Response time: 6.99 seconds.\n",
      "Response 13 of 15 complete.\n",
      "Response time: 7.12 seconds.\n",
      "Response 5 of 15 complete.\n",
      "Response time: 10.45 seconds.\n",
      "Link 1 Complete\n",
      "Starting Link 2:\n",
      "Response 1 of 5 complete.\n",
      "Response time: 5.64 seconds.\n",
      "Response 4 of 5 complete.\n",
      "Response time: 6.04 seconds.\n",
      "Response 2 of 5 complete.\n",
      "Response time: 7.42 seconds.\n",
      "Response 3 of 5 complete.\n",
      "Response time: 7.78 seconds.\n",
      "Response 5 of 5 complete.\n",
      "Response time: 8.29 seconds.\n",
      "Link 2 Complete\n",
      "Starting Link 3:\n",
      "Link 3 Complete\n",
      "Moore et al. (2022) conducted a comprehensive review of the safety and effectiveness of N-methyl-D-aspartate (NMDA) receptor antagonists for the treatment of depression in Pharmacotherapy. The article discusses the potential benefits of these drugs in treating depression and other psychiatric conditions while also highlighting the safety concerns associated with their use.\n",
      "\n",
      "Ketamine and esketamine, two NMDA receptor antagonists, have shown promising results in small trials for the treatment of depression. However, larger trials of esketamine nasal spray failed to replicate the positive outcomes seen in smaller studies. Safety concerns have also arisen due to animal toxicology studies of drug-induced abnormal neuron structures. Moreover, chronic ketamine exposure has been found to induce permanent impairment of brain functions in adolescent cynomolgus monkeys and hyperphosphorylated tau in the brains of mice and monkeys with long-term administration of ketamine.\n",
      "\n",
      "The altered mental state induced by these drugs varies with dosage, duration, and the patient's mental health. Studies have demonstrated that altered consciousness can range from mild transient euphoria to clinically significant psychosis. There are also concerns about tolerance, overdose, and addiction associated with repeated exposure to ketamine and esketamine.\n",
      "\n",
      "Despite the potential benefits of using these drugs, the review highlights the need for further research to fully understand their safety and effectiveness. The FDA has also alerted healthcare professionals to the potential risks associated with compounded ketamine nasal spray.\n",
      "\n",
      "The clinical trials for esketamine did not demonstrate a statistically significant benefit in reducing suicidality. The benefit in treating depression may have largely been due to the modality of treatment, rather than the pharmacological effect of the drug. The studies of longer-term use of these drugs were limited and often flawed, and the abnormal vacuoles created by their extended use may exceed the self-repair capacity of the neurons and trigger apoptotic cell death.\n",
      "\n",
      "Moreover, studies have shown that chronic ketamine exposure can lead to permanent impairment of brain functions in adolescent monkeys, hyperphosphorylated tau in the brains of mice and monkeys, and cortical thickness changes in chronic ketamine users. The use of ketamine has also been associated with various side effects, including dissociation, hallucinations, and cognitive impairment, and its long-term effects on mental health are not well studied.\n",
      "\n",
      "In conclusion, the expanding use of fast-acting NMDA receptor antagonists for psychiatric disorders is a significant risk to the public. However, their effectiveness and long-term safety are not well established. The primary precaution for managing the risks associated with these drugs is the administration under medical supervision and monitoring following administration. The review highlights the need for further research to fully understand their safety and effectiveness.\n",
      "\n",
      "Reference: Moore, T. J., Furberg, C. D., & Mattison, D. R. (2022). NMDA receptor antagonists for depression: A multidisciplinary review of safety and effectiveness. Pharmacotherapy, 42(5), 567-579.\n"
     ]
    }
   ],
   "source": [
    "async_chain = AsyncChain(doc)\n",
    "await async_chain.link_1()\n",
    "await async_chain.link_2()\n",
    "async_chain.link_3()\n",
    "async_chain.print_link_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moore et al. (2022) conducted a comprehensive review of the safety and effectiveness of N-methyl-D-aspartate (NMDA) receptor antagonists for the treatment of depression in Pharmacotherapy. The article discusses the potential benefits of these drugs in treating depression and other psychiatric conditions while also highlighting the safety concerns associated with their use.\n",
      "\n",
      "Ketamine and esketamine, two NMDA receptor antagonists, have shown promising results in small trials for the treatment of depression. However, larger trials of esketamine nasal spray failed to replicate the positive outcomes seen in smaller studies. Safety concerns have also arisen due to animal toxicology studies of drug-induced abnormal neuron structures. Moreover, chronic ketamine exposure has been found to induce permanent impairment of brain functions in adolescent cynomolgus monkeys and hyperphosphorylated tau in the brains of mice and monkeys with long-term administration of ketamine.\n",
      "\n",
      "The altered mental state induced by these drugs varies with dosage, duration, and the patient's mental health. Studies have demonstrated that altered consciousness can range from mild transient euphoria to clinically significant psychosis. There are also concerns about tolerance, overdose, and addiction associated with repeated exposure to ketamine and esketamine.\n",
      "\n",
      "Despite the potential benefits of using these drugs, the review highlights the need for further research to fully understand their safety and effectiveness. The FDA has also alerted healthcare professionals to the potential risks associated with compounded ketamine nasal spray.\n",
      "\n",
      "The clinical trials for esketamine did not demonstrate a statistically significant benefit in reducing suicidality. The benefit in treating depression may have largely been due to the modality of treatment, rather than the pharmacological effect of the drug. The studies of longer-term use of these drugs were limited and often flawed, and the abnormal vacuoles created by their extended use may exceed the self-repair capacity of the neurons and trigger apoptotic cell death.\n",
      "\n",
      "Moreover, studies have shown that chronic ketamine exposure can lead to permanent impairment of brain functions in adolescent monkeys, hyperphosphorylated tau in the brains of mice and monkeys, and cortical thickness changes in chronic ketamine users. The use of ketamine has also been associated with various side effects, including dissociation, hallucinations, and cognitive impairment, and its long-term effects on mental health are not well studied.\n",
      "\n",
      "In conclusion, the expanding use of fast-acting NMDA receptor antagonists for psychiatric disorders is a significant risk to the public. However, their effectiveness and long-term safety are not well established. The primary precaution for managing the risks associated with these drugs is the administration under medical supervision and monitoring following administration. The review highlights the need for further research to fully understand their safety and effectiveness.\n",
      "\n",
      "Reference: Moore, T. J., Furberg, C. D., & Mattison, D. R. (2022). NMDA receptor antagonists for depression: A multidisciplinary review of safety and effectiveness. Pharmacotherapy, 42(5), 567-579.\n"
     ]
    }
   ],
   "source": [
    "async_chain.print_link_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d30dbc225a77f624d100d49fcf625dcab10209cefe14c68d9c5591ea408b94d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

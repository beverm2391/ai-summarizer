{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../.env\")\n",
    "api_key = os.environ.get('OPENAI-API-KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.llms import OpenAI\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from langchain.prompts import BasePromptTemplate\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prevents the metadata from being None which causes errors with the vectorstore\n",
    "def sanitize_metadata(data):\n",
    "    for item in data:\n",
    "        meta = item.metadata\n",
    "        for key, value in meta.items():\n",
    "            if value is None:\n",
    "                meta[key] = \"\"\n",
    "    return data\n",
    "\n",
    "def unpack (data):\n",
    "    return [{'page' : idx + 1, 'content' : page.page_content, 'metadata' : page.metadata} for idx, page in enumerate(data)]\n",
    "\n",
    "def dot_product_similarity(doc_data: List[Dict], query_data: Dict) -> List[Tuple[int, float]]:\n",
    "    query_embedding = query_data['embedding']\n",
    "    doc_embeddings = [page['embedding'] for page in doc_data]\n",
    "    tuples_list = [(page['page'], np.dot(query_embedding, embedding)) for page, embedding in zip(doc_data, doc_embeddings)]\n",
    "    ordered_tuples = sorted(tuples_list, key=itemgetter(1), reverse=True)\n",
    "    top_five_tuples = ordered_tuples[:5]\n",
    "    return top_five_tuples\n",
    "\n",
    "def embed_query(query: str):\n",
    "    base_embeddings = OpenAIEmbeddings()\n",
    "    embedding = base_embeddings.embed_query(query)\n",
    "    return {\"query\" : query, \"embedding\" : embedding}\n",
    "\n",
    "def embed_doc(text_list : List[str]):\n",
    "    base_embeddings = OpenAIEmbeddings()\n",
    "    doc_embeddings = base_embeddings.embed_documents(text_list)\n",
    "    return doc_embeddings\n",
    "\n",
    "def get_context(query_data, doc_data: List[Dict]) -> List[Dict]:\n",
    "    top_five_tuples = dot_product_similarity(doc_data, query_data)\n",
    "    context = []\n",
    "    for item in top_five_tuples:\n",
    "        page = item[0]\n",
    "        data = {'page': page, 'similarity' : item[1], 'text': doc_data[page - 1]['content'], 'metadata' : doc_data[page - 1]['metadata']}\n",
    "        context.append(data)\n",
    "    return context\n",
    "\n",
    "def get_tokens(string: str, model: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def format_context(context: List[Dict], model: str, token_limit : int) -> str:\n",
    "    \"\"\"Returns a string of the first 1024 tokens of the context.\"\"\"\n",
    "    context_string = \"\"\n",
    "    meta_list = []\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    for idx, item in enumerate(context):\n",
    "        sanitized_text = item['text'].replace(\"\\n\", \" \")\n",
    "        context_string += f\"Page: {item['page']}\\n\\nText: {sanitized_text}\\n\\n\"\n",
    "        meta_list.append(item['metadata'])\n",
    "        tokens = get_tokens(context_string, model)\n",
    "        if tokens > token_limit:\n",
    "            encoded_text = encoding.encode(context_string)\n",
    "            # cut it down to the token limit\n",
    "            encoded_text = encoded_text[:token_limit]\n",
    "            # decode it back to a string\n",
    "            context_string = encoding.decode(encoded_text)\n",
    "            # some testing to make sure it worked\n",
    "            tokens = get_tokens(context_string, model)\n",
    "            assert tokens <= token_limit, f\"format context function failed to cut context down far enough. tokens: {tokens}\"\n",
    "            break\n",
    "    return context_string, meta_list\n",
    "\n",
    "class DocQAPromptTemplate(BasePromptTemplate, BaseModel):\n",
    "    \"\"\" A custom prompt template that takes a query and document data, and formats the prompt template to provide the formatted context + query to the language model. \"\"\"\n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v):\n",
    "        \"\"\" Validate that the input variables are correct. \"\"\"\n",
    "        if len(v) != 2:\n",
    "            raise ValueError(\"DocQAPromptTemplate must have two input variables: query and context.\")\n",
    "        return v\n",
    "    \n",
    "    def format(self, query, formatted_context) -> str:\n",
    "        # Get the source code of the function\n",
    "        instruction = \"Answer the query with a lengthy, deatiled reponse, to the best of your ability based on the provided context. If the question isn't relevant to the context, tell me that and briefly describe the context.\"\n",
    "        # Generate the prompt to be sent to the language model\n",
    "        prompt = f\"INSTRUCTION:\\n{instruction}\\n\\nCONTEXT:\\n{formatted_context}\\n\\nQUERY:\\n{query}\\n\\nOUTPUT:\\n\"\n",
    "        return prompt\n",
    "    \n",
    "    def _prompt_type(self):\n",
    "        return \"doc context + query\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../data/powers2017.pdf\"\n",
    "\n",
    "loader = PyMuPDFLoader(fpath)\n",
    "# load the data\n",
    "unsanitized = loader.load()\n",
    "# make sure the metadata is not None\n",
    "data = sanitize_metadata(unsanitized)\n",
    "\n",
    "# get the doc embeddings\n",
    "doc_embeddings = embed_doc([page.page_content for page in data])\n",
    "\n",
    "# unpack the data and add the embeddings\n",
    "mongodoc = unpack(data)\n",
    "mongodoc = [{**page, \"embedding\": embedding} for page, embedding in zip(mongodoc, doc_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_doc(fpath):\n",
    "    loader = PyMuPDFLoader(fpath)\n",
    "    # load the data\n",
    "    unsanitized = loader.load()\n",
    "    # make sure the metadata is not None\n",
    "    data = sanitize_metadata(unsanitized)\n",
    "\n",
    "    # get the doc embeddings\n",
    "    doc_embeddings = embed_doc([page.page_content for page in data])\n",
    "\n",
    "    # unpack the data and add the embeddings\n",
    "    mongodoc = unpack(data)\n",
    "    mongodoc = [{**page, \"embedding\": embedding} for page, embedding in zip(mongodoc, doc_embeddings)]\n",
    "    \n",
    "    return mongodoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_doc(query: str, mongodoc: List[Dict], model: str, token_limit: int):\n",
    "    # embed the query\n",
    "    query_data = embed_query(query)\n",
    "    # get the context\n",
    "    context = get_context(query_data, mongodoc)\n",
    "    # format the context\n",
    "    formatted_context, meta_list = format_context(context, model, token_limit)\n",
    "    # format the prompt\n",
    "    prompt_template = DocQAPromptTemplate(input_variables=[\"query\", \"formatted_context\"])\n",
    "    prompt = prompt_template.format(query, formatted_context)\n",
    "    # query the language model\n",
    "    llm = OpenAI(temperature=0.7)\n",
    "    response = llm(prompt)\n",
    "    # return the response, the metadata, and the context\n",
    "    return response, meta_list, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, meta_list, context = query_doc(\"What is the purpose of the study?\", mongodoc, \"text-davinci-003\", 2800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
